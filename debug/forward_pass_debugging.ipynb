{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1acade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "print(os.getcwd())\n",
    "import torch\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8' \n",
    "seed = 21\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.use_deterministic_algorithms(False)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbcb35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data_pipeline import DataPipeline\n",
    "pipeline = DataPipeline(components_csv='datasets/components.csv')\n",
    "canonical_data, graph_list = pipeline.run_pipeline(raw_csv='datasets/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb19f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules.datasplit_module as dsm\n",
    "# --- Split graphs ---\n",
    "random.shuffle(graph_list)\n",
    "sampled_graph_list = graph_list\n",
    "train, val, test = \\\n",
    "    dsm.system_disjoint_split(sampled_graph_list, random_state=seed, stratify_by_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fefa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train[:1000],\n",
    "    batch_size=512,\n",
    "    shuffle=True,\n",
    "    follow_batch=['component_batch']  # Creates component_batch_batch automatically!\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val[:1000],\n",
    "    batch_size=512,\n",
    "    shuffle=False,\n",
    "    follow_batch=['component_batch']\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test[:1000],\n",
    "    batch_size=512,\n",
    "    shuffle=False,\n",
    "    follow_batch=['component_batch']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faa72eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INPUT DATA STRUCTURE ===\n",
      "batch.x: torch.Size([146, 18])\n",
      "batch.edge_index: torch.Size([2, 274])\n",
      "batch.edge_attr: torch.Size([274, 4])\n",
      "batch.mol_batch: torch.Size([146]), unique: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11], device='cuda:0')\n",
      "batch.component_batch: torch.Size([12])\n",
      "batch.component_batch_batch: torch.Size([12])\n",
      "batch.component_mole_frac: torch.Size([12])\n",
      "\n",
      "=== FORWARD PASS ===\n",
      "tensor([0.6084, 0.6077, 0.6123, 0.6148, 0.6072, 0.6154, 0.6060, 0.6100, 0.6096,\n",
      "        0.6095, 0.6069, 0.6146], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "[OK] Forward pass successful!\n",
      "gamma_calc shape: torch.Size([12])\n",
      "latent_vectors shape: torch.Size([12, 5])\n",
      "comp_emb shape: torch.Size([12, 5])\n",
      "gradient tracking: torch.Size([12, 5])\n",
      "\n",
      "=== EXPECTED vs ACTUAL ===\n",
      "Expected predictions: 12 systems\n",
      "Expected latent_vectors: 12 components\n",
      "\n",
      "=== GRADIENT TRACKING ===\n",
      "mole_frac.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "from modules.dtmpnn import DTMPNN\n",
    "\n",
    "# Example: take 5 mixtures from train\n",
    "test_batch = DataLoader(train[:10], batch_size=5, shuffle=False, follow_batch=['component_batch'])\n",
    "batch = next(iter(test_batch))\n",
    "\n",
    "model = DTMPNN(\n",
    "    node_dim=batch.x.shape[1],\n",
    "    edge_dim=batch.edge_attr.shape[1],\n",
    "    graph_hidden_dim=5,\n",
    "    latent_dim=5,\n",
    "    context_dim=5,\n",
    "    graph_layers=2,\n",
    "    track_grad=True,\n",
    "    constraint_type='hard'\n",
    ").cuda()\n",
    "\n",
    "device = next(model.parameters()).device\n",
    "batch = batch.to(device)\n",
    "\n",
    "print(\"=== INPUT DATA STRUCTURE ===\")\n",
    "print(f\"batch.x: {batch.x.shape}\")\n",
    "print(f\"batch.edge_index: {batch.edge_index.shape}\")\n",
    "print(f\"batch.edge_attr: {batch.edge_attr.shape}\")\n",
    "print(f\"batch.mol_batch: {batch.mol_batch.shape}, unique: {batch.mol_batch.unique()}\")\n",
    "print(f\"batch.component_batch: {batch.component_batch.shape}\")\n",
    "print(f\"batch.component_batch_batch: {batch.component_batch_batch.shape}\")\n",
    "print(f\"batch.component_mole_frac: {batch.component_mole_frac.shape}\")\n",
    "\n",
    "print(\"\\n=== FORWARD PASS ===\")\n",
    "try:\n",
    "    gamma_calc, latent_vectors, comp_emb = model(batch)\n",
    "    print(\"[OK] Forward pass successful!\")\n",
    "    print(f\"gamma_calc shape: {gamma_calc.shape}\")\n",
    "    print(f\"latent_vectors shape: {latent_vectors.shape}\")\n",
    "    print(f\"comp_emb shape: {comp_emb.shape}\")\n",
    "    print(f\"gradient tracking: {comp_emb.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Forward pass failed!\")\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n=== EXPECTED vs ACTUAL ===\")\n",
    "print(f\"Expected predictions: {batch.component_gammas.shape[0]} systems\")\n",
    "print(f\"Expected latent_vectors: {batch.component_batch.shape[0]} components\")\n",
    "\n",
    "print(\"\\n=== GRADIENT TRACKING ===\")\n",
    "print(\"mole_frac.requires_grad =\", batch.component_mole_frac.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6356dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDMPNN\n",
    "from modules.dtmpnn import DTMPNN\n",
    "from modules.loss_func import GibbsDuhemLoss\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Example: take 5 mixtures from train\n",
    "test_batch = DataLoader(train[:10], batch_size=5, shuffle=False, follow_batch=['component_batch'])\n",
    "batch = next(iter(test_batch))\n",
    "model = DTMPNN(\n",
    "    node_dim=batch.x.shape[1],\n",
    "    edge_dim=batch.edge_attr.shape[1],\n",
    "    graph_hidden_dim=1,\n",
    "    latent_dim=1,\n",
    "    context_dim=1,\n",
    "    graph_layers=1,\n",
    "    track_grad=True,\n",
    "    constraint_type='hard'\n",
    ").cuda()\n",
    "\n",
    "# Gibbs-Duhem loss\n",
    "gd_loss_fn = GibbsDuhemLoss()\n",
    "device = next(model.parameters()).device\n",
    "batch = batch.to(device)\n",
    "\n",
    "# Forward pass through the model\n",
    "gamma_calc, latent_vectors, comp_emb = model(batch)\n",
    "\n",
    "print(\"gamma_calc shape:\", gamma_calc.shape)\n",
    "print(\"latent_vectors shape:\", latent_vectors.shape)\n",
    "print(\"comp_emb shape:\", comp_emb.shape)\n",
    "\n",
    "print(\"\\n=== Diagnostic Info ===\")\n",
    "print(\"Mole frac requires_grad:\", batch.component_mole_frac.requires_grad)\n",
    "print(\"Latent vectors requires_grad:\", latent_vectors.requires_grad)\n",
    "print(\"Number of unique batches:\", torch.unique(batch.component_batch_batch).numel())\n",
    "print(\"Components per batch:\", [(batch.component_batch_batch == i).sum().item() \n",
    "                                 for i in torch.unique(batch.component_batch_batch)])\n",
    "gd_loss = gd_loss_fn(batch, gamma_calc)\n",
    "print(\"GD loss:\", gd_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba04259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_gibbs_duhem_losses(batch, gamma_calc):\n",
    "    import torch.autograd as autograd\n",
    "    \"\"\"Test Gibbs-Duhem loss for different loss types.\"\"\"\n",
    "    loss_types = ['explicit', 'optimized']\n",
    "    results = {}\n",
    "    \n",
    "    for loss_type in loss_types:\n",
    "        print(f\"\\n=== Testing loss type: {loss_type} ===\")\n",
    "        gd_loss_fn = GibbsDuhemLoss(loss_type=loss_type)\n",
    "        gd_loss = gd_loss_fn(batch, gamma_calc)\n",
    "        loss_value = gd_loss.item()\n",
    "        print(f\"GD loss computed: {loss_value}\")\n",
    "        results[loss_type] = loss_value\n",
    "    \n",
    "    return results\n",
    "\n",
    "results = test_gibbs_duhem_losses(batch, gamma_calc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vle-dtmpnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
