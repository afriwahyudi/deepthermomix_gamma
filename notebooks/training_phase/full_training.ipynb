{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1acade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.chdir(\"../..\")\n",
    "print(os.getcwd())\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8' \n",
    "seed = 21\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.use_deterministic_algorithms(False)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5c2cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data_pipeline import DataPipeline\n",
    "pipeline = DataPipeline(components_csv='datasets/components.csv')\n",
    "canonical_data, graph_list = pipeline.run_pipeline(raw_csv='datasets/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb19f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules.datasplit_module as dsm\n",
    "# --- Split graphs ---\n",
    "random.shuffle(graph_list)\n",
    "sampled_graph_list = graph_list\n",
    "train, val, test = \\\n",
    "    dsm.system_disjoint_split(sampled_graph_list, random_state=seed, stratify_by_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fefa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train,\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    "    follow_batch=['component_batch']\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val,\n",
    "    batch_size=1024,\n",
    "    shuffle=False,\n",
    "    follow_batch=['component_batch']\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test,\n",
    "    batch_size=1024,\n",
    "    shuffle=False,\n",
    "    follow_batch=['component_batch']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed26e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules.trainer_module as tm\n",
    "import modules.dtmpnn as gm\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\"\"\" \n",
    "    To involve GD \n",
    "    we need to set\n",
    "    both gradient tracking and include to be True\n",
    "\"\"\"\n",
    "track_grad = True\n",
    "include_gd = False\n",
    "gd_weight = 1\n",
    "\n",
    "# Create model\n",
    "model = gm.DTMPNN(\n",
    "    node_dim=train[0].x.shape[1],\n",
    "    edge_dim=train[0].edge_attr.shape[1],\n",
    "    graph_hidden_dim=256,\n",
    "    latent_dim=256,\n",
    "    context_dim=256,\n",
    "    graph_layers=3,\n",
    "    track_grad=True\n",
    ").to(device)\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = tm.DTMPNNTrainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    include_gd=include_gd,\n",
    "    device=device,\n",
    "    lr=0.0001,\n",
    "    weight_decay=0,\n",
    "    data_driven_weight=1.0,\n",
    "    gd_weight=gd_weight\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = trainer.train(\n",
    "    epochs=100,\n",
    "    save_dir='notebooks/training_phase/single_checkpoints',\n",
    "    log_file_path='notebooks/training_phase/single_checkpoints/training_run_log.txt',\n",
    "    save_best=True,\n",
    "    save_every=25\n",
    ")\n",
    "\n",
    "# Plot training curves\n",
    "trainer.plot_history(save_path=f'notebooks/training_phase/single_checkpoints/training_history_GD_Backprop_{include_gd}.png')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf9f537",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f52d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test batching\n",
    "for batch in train_loader:\n",
    "    batch = batch.to('cuda')  # Move batch, not loader\n",
    "    print(\"=== Batch Structure ===\")\n",
    "    print(f\"Number of graphs (mixtures): {batch.num_graphs}\")\n",
    "    print(f\"Total nodes: {batch.x.shape[0]}\")\n",
    "    print(f\"Total components: {len(batch.component_mole_frac)}\")\n",
    "    print(f\"Total gammas: {len(batch.component_gammas)}\")\n",
    "    print(f\"\\nmol_batch (node-to-molecule): {batch.mol_batch}\")\n",
    "    print(f\"mol_batch unique values: {batch.mol_batch.unique()}\")\n",
    "    print(f\"\\ncomponent_batch_batch (component-to-mixture): {batch.component_batch_batch}\")\n",
    "    print(f\"component_batch_batch unique: {batch.component_batch_batch.unique()}\")\n",
    "    \n",
    "    # Run model\n",
    "    y_pred, latent_vecs, comp_emb = model(batch)\n",
    "    print(f\"\\n=== Model Outputs ===\")\n",
    "    print(f\"y_pred shape: {y_pred.shape}\")\n",
    "    print(f\"component_gammas shape: {batch.component_gammas.shape}\")\n",
    "    print(f\"comp_emb shape: {comp_emb.shape}\")\n",
    "    print(f\"latent_vecs shape: {latent_vecs.shape}\")\n",
    "    \n",
    "    print(f\"\\n=== Alignment Check ===\")\n",
    "    print(f\"Do shapes match? y_pred vs gammas: {y_pred.shape == batch.component_gammas.shape}\")\n",
    "    \n",
    "    break  # Just test first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c727dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    batch = batch.to('cuda')\n",
    "    y_pred, latent_vecs, comp_emb = model(batch)\n",
    "    \n",
    "    print(\"=== Value Check ===\")\n",
    "    print(f\"y_pred: {y_pred}\")\n",
    "    print(f\"y_true: {batch.component_gammas}\")\n",
    "    print(f\"Difference: {y_pred - batch.component_gammas}\")\n",
    "    \n",
    "    # Check if predictions are reasonable\n",
    "    print(f\"\\ny_pred range: [{y_pred.min():.4f}, {y_pred.max():.4f}]\")\n",
    "    print(f\"y_true range: [{batch.component_gammas.min():.4f}, {batch.component_gammas.max():.4f}]\")\n",
    "    \n",
    "    # Compute loss manually\n",
    "    loss = ((y_pred - batch.component_gammas) ** 2).mean()\n",
    "    print(f\"\\nManual MSE: {loss.item():.6f}\")\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ec08bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import modules.trainer_module as tm\n",
    "# Load best model and evaluate\n",
    "print(\"Loading best model for final evaluation...\")\n",
    "print(\"=\"*70)\n",
    "trainer.load_checkpoint('notebooks/training_phase/single_checkpoints/checkpoint_epoch_150.pt')\n",
    "# --- Refactored Final Evaluation Script ---\n",
    "def evaluate_and_print_results(trainer_obj, loader, set_name):\n",
    "    \"\"\"\n",
    "    Runs validation and prints formatted results for a given data set,\n",
    "    respecting the dynamic data loss name and GD printing symmetry.\n",
    "    \"\"\"\n",
    "    _, data_loss, gd_loss, rmse, mae, r2, mape = trainer_obj.validate(loader)\n",
    "\n",
    "    gd_print = f\"Test GD      : {gd_loss:.4f}\"\n",
    "\n",
    "\n",
    "    data_loss_name = trainer_obj.datadriven_loss_name\n",
    "\n",
    "    print(f\"\\nFinal Results {set_name}:\")\n",
    "    print(f\"Test {data_loss_name:<8}: {data_loss:.4f}\")\n",
    "    print(gd_print)\n",
    "    print(f\"Test RMSE    : {rmse:.4f}\")\n",
    "    print(f\"Test MAE     : {mae:.4f}\")\n",
    "    print(f\"Test R2      : {r2:.4f}\")\n",
    "    print(f\"Test MAPE    : {mape:.4f}%\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "\n",
    "# Evaluate across all three sets using the new function\n",
    "evaluate_and_print_results(trainer, trainer.train_loader, \"TRAINING SET\")\n",
    "evaluate_and_print_results(trainer, trainer.val_loader, \"VALIDATION SET\")\n",
    "evaluate_and_print_results(trainer, trainer.test_loader, \"TESTING SET\") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a4793b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # Create model\n",
    "model = model\n",
    "# --- Forward pass + backprop ---\n",
    "trying_loader = DataLoader(\n",
    "    dataset=test,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    follow_batch=['component_batch']\n",
    ")\n",
    "model.eval()\n",
    "target_batch = 9\n",
    "for i, batched_data in enumerate(trying_loader):\n",
    "    if i == target_batch:\n",
    "        batched_data = batched_data.to(device)\n",
    "        y_pred, latent_vectors, comp_emb = model(batched_data)\n",
    "        print(\"\\n\" + \"=\"*120)\n",
    "        print(\"Forward Pass inputs:\")\n",
    "        print(f\"Component names                                     : {batched_data.component_names}\")\n",
    "        print(f\"Component mole fractions                            : {batched_data.component_mole_frac}\")\n",
    "        print(\"\\n\" + \"=\"*120)\n",
    "        print(\"Forward Pass Outputs:\")        \n",
    "\n",
    "        print(\"\\n\" + \"=\"*120)\n",
    "        print(\"Solvent subsystem analysis:\")            \n",
    "        print(f\"Aggregated latent vector (gamma_i)                  : {(latent_vectors.mean(dim=1).view(1,-1)).detach()}\")\n",
    "        print(f\"Hypothetical Excess Gibss Energy (G_i_excess)       : {(latent_vectors.mean(dim=1).view(1,-1) * 8.314 * (batched_data.T * batched_data.T_std + batched_data.T_mean).view(-1,1)).detach()} J/mol\")\n",
    "        print(f\"Hypothetical Sum of Excess Gibss Energy             : {((latent_vectors.mean(dim=1).view(1,-1) * 8.314 * (batched_data.T * batched_data.T_std + batched_data.T_mean).view(-1,1)).detach()).sum(dim=1)} J/mol\")\n",
    "        print(f\"Aggregated components embedding                     : {(comp_emb.mean(dim=1).view(1,-1)).detach()}\")\n",
    "        break \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vle-dtmpnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
