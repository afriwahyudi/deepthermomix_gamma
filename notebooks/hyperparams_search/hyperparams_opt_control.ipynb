{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1acade7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\aw_workspace\\main_project\\vle_dtmpnn\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "os.chdir(\"../..\")\n",
    "print(os.getcwd())\n",
    "\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8' \n",
    "seed = 21\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.use_deterministic_algorithms(False)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ba4d8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 859 components from registry\n",
      "============================================================\n",
      "EXECUTION STARTED\n",
      "============================================================\n",
      "\n",
      "Step 1: Parsing raw data...\n",
      "\n",
      "Step 2: Parsing systems...\n",
      "Identified 80000 unique systems\n",
      "\n",
      "Step 3: Parsing mole fractions and activity coefficients...\n",
      "\n",
      "Step 4: Constructing molecular graphs...\n",
      "\n",
      "=== DIAGNOSTIC SUMMARY ===\n",
      "Total input rows: 440000\n",
      "Graphs created: 440000\n",
      "Graphs missing: 0\n",
      "\n",
      "Skip reasons:\n",
      "  - Systems with no valid components: 0\n",
      "  - Component instances missing SMILES: 0\n",
      "  - Component instances with invalid molecules: 0\n",
      "\n",
      "First 10 skipped systems:\n",
      "\n",
      "============================================================\n",
      "PIPELINE COMPLETE!\n",
      "Processed 440000 data points\n",
      "Created 440000 molecular graphs\n",
      "Unique systems: 80000\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from modules.data_pipeline import DataPipeline\n",
    "pipeline = DataPipeline(components_csv='datasets/components.csv')\n",
    "canonical_data, graph_list = pipeline.run_pipeline(raw_csv='datasets/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcb19f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component distribution:\n",
      "  Train: {2: 196000, 3: 112000}\n",
      "  Val:   {2: 42000, 3: 24000}\n",
      "  Test:  {2: 42000, 3: 24000}\n",
      "\n",
      "Datapoints -> Train: 308000, Val: 66000, Test: 66000\n",
      "Unique systems -> Train: 56000, Val: 12000, Test: 12000\n"
     ]
    }
   ],
   "source": [
    "import modules.datasplit_module as dsm\n",
    "random.shuffle(graph_list)\n",
    "sampled_graph_list = graph_list\n",
    "train, val, test = \\\n",
    "    dsm.system_disjoint_split(sampled_graph_list, random_state=seed, stratify_by_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8fefa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train,\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    "    follow_batch=['component_batch']\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val,\n",
    "    batch_size=1024,\n",
    "    shuffle=False,\n",
    "    follow_batch=['component_batch']\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test,\n",
    "    batch_size=1024,\n",
    "    shuffle=False,\n",
    "    follow_batch=['component_batch']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60bbf9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Configuration ---\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "track_grad = True\n",
    "include_gd = False\n",
    "N_TRIALS = 20\n",
    "N_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ed26e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Include GD: False\n",
      "Trials: 20\n",
      "Epochs per trial: 50\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "import modules.trainer_module as tm\n",
    "import modules.dtmpnn as gm\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import sys\n",
    "\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Include GD: {include_gd}\")\n",
    "print(f\"Trials: {N_TRIALS}\")\n",
    "print(f\"Epochs per trial: {N_EPOCHS}\")\n",
    "\n",
    "def objective(trial: optuna.trial.Trial):\n",
    "    \"\"\"\n",
    "    This function takes an optuna 'trial' object,\n",
    "    builds a model, trains it, and returns the best validation loss.\n",
    "    \"\"\"\n",
    "    log_dir = Path(f\"notebooks/hyperparams_search/HPO_reports/optuna_logs_{include_gd}\")\n",
    "    log_dir.mkdir(exist_ok=True, parents=True)\n",
    "    log_file_path = log_dir / f'trial_{trial.number}.log'\n",
    "\n",
    "    # --- 1. DEFINE THE HYPERPARAMETER SEARCH SPACE ---\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-7, 1e-4, log=True)\n",
    "    gd_weight = 1.0\n",
    "    graph_hidden_dim = trial.suggest_categorical('graph_hidden_dim', [16, 32, 64, 128])\n",
    "    latent_dim = trial.suggest_categorical('latent_dim', [16, 32, 64])\n",
    "    context_dim = trial.suggest_categorical('context_dim', [16, 32, 64])\n",
    "    graph_layers = trial.suggest_int('graph_layers', 2, 5)\n",
    "\n",
    "    # --- 2. RUN THE TRIAL ---\n",
    "    try:\n",
    "        model = gm.DTMPNN(\n",
    "                node_dim=train[0].x.shape[1],\n",
    "                edge_dim=train[0].edge_attr.shape[1],\n",
    "                graph_hidden_dim=graph_hidden_dim,\n",
    "                latent_dim=latent_dim,\n",
    "                context_dim=context_dim,\n",
    "                graph_layers=graph_layers,\n",
    "                track_grad=True\n",
    "                        ).to(device)\n",
    "\n",
    "        trainer = tm.DTMPNNTrainer(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            test_loader=test_loader,\n",
    "            include_gd=include_gd,\n",
    "            device=device,\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay,\n",
    "            gd_weight=gd_weight\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        trainer.train(\n",
    "            epochs=N_EPOCHS,\n",
    "            save_dir=f'notebooks/hyperparams_search/HPO_reports/optuna_checkpoints_{include_gd}/trial_{trial.number}',\n",
    "            log_file_path=log_file_path,\n",
    "            save_best=False,\n",
    "            save_every=None,\n",
    "            optuna_trial=trial\n",
    "        )\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # --- 3. RETURN THE METRIC TO MINIMIZE ---\n",
    "        return trainer.best_val_loss\n",
    "\n",
    "    except optuna.TrialPruned:\n",
    "        print(f\"Trial {trial.number} was pruned.\")\n",
    "        torch.cuda.empty_cache()\n",
    "        raise\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Trial {trial.number} failed with error: {e}\", file=sys.stderr)\n",
    "        torch.cuda.empty_cache()\n",
    "        return float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc0f4e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Study Runner ---\n",
    "def run_study():\n",
    "    pruner = MedianPruner(\n",
    "        n_startup_trials=5,\n",
    "        n_warmup_steps=5,\n",
    "        interval_steps=1\n",
    "    )\n",
    "    \n",
    "    study_name = f\"DTMPNN_hpo_{'gd' if include_gd else 'no_gd'}\"\n",
    "    study_db_path = f\"sqlite:///notebooks/hyperparams_search/HPO_reports/dashboard/master_hpo_study.db\"\n",
    "    \n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        storage=study_db_path,\n",
    "        load_if_exists=True,\n",
    "        direction='minimize',\n",
    "        pruner=pruner\n",
    "    )\n",
    "    \n",
    "    print(f\"--- Starting/Resuming study: {study_name} ---\")\n",
    "    print(f\"--- Database at: {study_db_path} ---\")\n",
    "\n",
    "    try:\n",
    "        study.optimize(\n",
    "            objective, \n",
    "            n_trials=N_TRIALS,\n",
    "            timeout=None,\n",
    "            gc_after_trial=True\n",
    "        ) \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"--- HPO interrupted by user. Study is saved. ---\")\n",
    "    \n",
    "    print(f\"--- Study complete ---\")\n",
    "    \n",
    "    # --- 5. PRINT RESULTS ---\n",
    "    pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "    completed_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "    \n",
    "    print(f\"Total trials: {len(study.trials)}\")\n",
    "    print(f\"  Completed: {len(completed_trials)}\")\n",
    "    print(f\"  Pruned:    {len(pruned_trials)}\")\n",
    "\n",
    "    if completed_trials:\n",
    "        print(f\"\\nBest trial:\")\n",
    "        best_trial = study.best_trial\n",
    "        print(f\"  Value (min val_loss): {best_trial.value:.6f}\")\n",
    "        print(f\"  Params: \")\n",
    "        for key, value in best_trial.params.items():\n",
    "            print(f\"    {key}: {value}\")\n",
    "    else:\n",
    "        print(\"No trials completed successfully.\")\n",
    "    \n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "902c287b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 14:39:08,452] Using an existing study with name 'DTMPNN_hpo_no_gd' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting/Resuming study: DTMPNN_hpo_no_gd ---\n",
      "--- Database at: sqlite:///notebooks/hyperparams_search/HPO_reports/dashboard/master_hpo_study.db ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 15:17:30,280] Trial 51 finished with value: 0.16409032585529182 and parameters: {'lr': 0.0014414995626272722, 'weight_decay': 2.2879840314182504e-07, 'graph_hidden_dim': 128, 'latent_dim': 64, 'context_dim': 16, 'graph_layers': 5}. Best is trial 48 with value: 0.15843770481072939.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Full log successfully finalized and written to: trial_51.log ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 15:49:57,408] Trial 52 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 43. ---\n",
      "Trial 52 was pruned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 16:31:32,362] Trial 53 finished with value: 0.1512628116286718 and parameters: {'lr': 0.0012293526076691823, 'weight_decay': 2.429199151209364e-07, 'graph_hidden_dim': 128, 'latent_dim': 64, 'context_dim': 16, 'graph_layers': 5}. Best is trial 53 with value: 0.1512628116286718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Full log successfully finalized and written to: trial_53.log ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 17:14:20,930] Trial 54 finished with value: 0.15216840482675112 and parameters: {'lr': 0.0010411605698050982, 'weight_decay': 1.0060964951517347e-07, 'graph_hidden_dim': 128, 'latent_dim': 64, 'context_dim': 16, 'graph_layers': 5}. Best is trial 53 with value: 0.1512628116286718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Full log successfully finalized and written to: trial_54.log ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 17:18:38,996] Trial 55 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 5. ---\n",
      "Trial 55 was pruned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 17:23:45,934] Trial 56 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 6. ---\n",
      "Trial 56 was pruned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 17:28:03,479] Trial 57 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 5. ---\n",
      "Trial 57 was pruned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 18:10:54,458] Trial 58 finished with value: 0.15141738997055934 and parameters: {'lr': 0.0010221095157197783, 'weight_decay': 4.360182667707147e-07, 'graph_hidden_dim': 128, 'latent_dim': 64, 'context_dim': 16, 'graph_layers': 5}. Best is trial 53 with value: 0.1512628116286718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Full log successfully finalized and written to: trial_58.log ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 18:15:12,059] Trial 59 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 5. ---\n",
      "Trial 59 was pruned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 18:19:31,444] Trial 60 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 5. ---\n",
      "Trial 60 was pruned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 19:02:59,054] Trial 61 finished with value: 0.15181168409494253 and parameters: {'lr': 0.0010151099487462466, 'weight_decay': 2.615389453337195e-07, 'graph_hidden_dim': 128, 'latent_dim': 64, 'context_dim': 16, 'graph_layers': 5}. Best is trial 53 with value: 0.1512628116286718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Full log successfully finalized and written to: trial_61.log ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 19:39:27,573] Trial 62 finished with value: 0.15352897632580537 and parameters: {'lr': 0.0010660069123260318, 'weight_decay': 2.443970189545713e-07, 'graph_hidden_dim': 128, 'latent_dim': 64, 'context_dim': 16, 'graph_layers': 5}. Best is trial 53 with value: 0.1512628116286718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Full log successfully finalized and written to: trial_62.log ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 19:42:30,380] Trial 63 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 5. ---\n",
      "Trial 63 was pruned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 19:45:32,704] Trial 64 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 5. ---\n",
      "Trial 64 was pruned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 19:49:47,735] Trial 65 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 7. ---\n",
      "Trial 65 was pruned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 19:52:51,263] Trial 66 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 5. ---\n",
      "Trial 66 was pruned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 19:55:53,530] Trial 67 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 5. ---\n",
      "Trial 67 was pruned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 20:07:58,457] Trial 68 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 20. ---\n",
      "Trial 68 was pruned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 20:11:02,247] Trial 69 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 5. ---\n",
      "Trial 69 was pruned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 20:14:05,798] Trial 70 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 5. ---\n",
      "Trial 70 was pruned.\n",
      "--- Study complete ---\n",
      "Total trials: 71\n",
      "  Completed: 35\n",
      "  Pruned:    35\n",
      "\n",
      "Best trial:\n",
      "  Value (min val_loss): 0.151263\n",
      "  Params: \n",
      "    lr: 0.0012293526076691823\n",
      "    weight_decay: 2.429199151209364e-07\n",
      "    graph_hidden_dim: 128\n",
      "    latent_dim: 64\n",
      "    context_dim: 16\n",
      "    graph_layers: 5\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Run the HPO Study ---\n",
    "if __name__ == \"__main__\":\n",
    "    Path(\"notebooks/hyperparams_search/HPO_reports\").mkdir(exist_ok=True)\n",
    "    Path(\"notebooks/hyperparams_search/HPO_reports/dashboard\").mkdir(exist_ok=True)\n",
    "    study = run_study()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vle-dtmpnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
