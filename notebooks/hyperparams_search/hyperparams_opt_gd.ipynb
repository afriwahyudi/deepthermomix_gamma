{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1acade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "os.chdir(\"../..\")\n",
    "print(os.getcwd())\n",
    "\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8' \n",
    "seed = 21\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.use_deterministic_algorithms(False)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10995fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data_pipeline import DataPipeline\n",
    "pipeline = DataPipeline(components_csv='datasets/components.csv')\n",
    "canonical_data, graph_list = pipeline.run_pipeline(raw_csv='datasets/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb19f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules.datasplit_module as dsm\n",
    "random.shuffle(graph_list)\n",
    "sampled_graph_list = graph_list\n",
    "train, val, test = \\\n",
    "    dsm.system_disjoint_split(sampled_graph_list, random_state=seed, stratify_by_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fefa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train,\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    "    follow_batch=['component_batch']\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val,\n",
    "    batch_size=1024,\n",
    "    shuffle=False,\n",
    "    follow_batch=['component_batch']\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test,\n",
    "    batch_size=1024,\n",
    "    shuffle=False,\n",
    "    follow_batch=['component_batch']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60bbf9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Configuration ---\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "track_grad = True\n",
    "include_gd = True\n",
    "N_TRIALS = 20\n",
    "N_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ed26e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Include GD: True\n",
      "Trials: 20\n",
      "Epochs per trial: 50\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "import modules.trainer_module as tm\n",
    "import modules.dtmpnn as gm\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import sys\n",
    "\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Include GD: {include_gd}\")\n",
    "print(f\"Trials: {N_TRIALS}\")\n",
    "print(f\"Epochs per trial: {N_EPOCHS}\")\n",
    "\n",
    "def objective(trial: optuna.trial.Trial):\n",
    "    \"\"\"\n",
    "    This function takes an optuna 'trial' object,\n",
    "    builds a model, trains it, and returns the best validation loss.\n",
    "    \"\"\"\n",
    "    log_dir = Path(f\"notebooks/hyperparams_search/HPO_reports/optuna_logs_{include_gd}\")\n",
    "    log_dir.mkdir(exist_ok=True, parents=True)\n",
    "    log_file_path = log_dir / f'trial_{trial.number}.log'\n",
    "\n",
    "    # --- 1. DEFINE THE HYPERPARAMETER SEARCH SPACE ---\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-7, 1e-4, log=True)\n",
    "    gd_weight = trial.suggest_float('gd_weight', 1e-3, 1, log=True)\n",
    "    \n",
    "    graph_hidden_dim = trial.suggest_categorical('graph_hidden_dim', [16, 32, 64, 128])\n",
    "    latent_dim = trial.suggest_categorical('latent_dim', [16, 32, 64])\n",
    "    context_dim = trial.suggest_categorical('context_dim', [16, 32, 64])\n",
    "    graph_layers = trial.suggest_int('graph_layers', 2, 5)\n",
    "\n",
    "    # --- 2. RUN THE TRIAL ---\n",
    "    try:\n",
    "        model = gm.DTMPNN(\n",
    "                node_dim=train[0].x.shape[1],\n",
    "                edge_dim=train[0].edge_attr.shape[1],\n",
    "                graph_hidden_dim=graph_hidden_dim,\n",
    "                latent_dim=latent_dim,\n",
    "                context_dim=context_dim,\n",
    "                graph_layers=graph_layers,\n",
    "                track_grad=True\n",
    "                        ).to(device)\n",
    "\n",
    "        trainer = tm.DTMPNNTrainer(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            test_loader=test_loader,\n",
    "            include_gd=include_gd,\n",
    "            device=device,\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay,\n",
    "            gd_weight=gd_weight\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        trainer.train(\n",
    "            epochs=N_EPOCHS,\n",
    "            save_dir=f'notebooks/hyperparams_search/HPO_reports/optuna_checkpoints_{include_gd}/trial_{trial.number}',\n",
    "            log_file_path=log_file_path,\n",
    "            save_best=False,\n",
    "            save_every=None,\n",
    "            optuna_trial=trial\n",
    "        )\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # --- 3. RETURN THE METRIC TO MINIMIZE ---\n",
    "        return trainer.best_val_loss\n",
    "\n",
    "    except optuna.TrialPruned:\n",
    "        print(f\"Trial {trial.number} was pruned.\")\n",
    "        torch.cuda.empty_cache()\n",
    "        raise\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Trial {trial.number} failed with error: {e}\", file=sys.stderr)\n",
    "        torch.cuda.empty_cache()\n",
    "        return float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc0f4e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Study Runner ---\n",
    "def run_study():\n",
    "    pruner = MedianPruner(\n",
    "        n_startup_trials=5,\n",
    "        n_warmup_steps=5,\n",
    "        interval_steps=1\n",
    "    )\n",
    "    \n",
    "    study_name = f\"DTMPNN_hpo_{'gd' if include_gd else 'no_gd'}\"\n",
    "    study_db_path = f\"sqlite:///notebooks/hyperparams_search/HPO_reports/dashboard/master_hpo_study.db\"\n",
    "    \n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        storage=study_db_path,\n",
    "        load_if_exists=True,\n",
    "        direction='minimize',\n",
    "        pruner=pruner\n",
    "    )\n",
    "    \n",
    "    print(f\"--- Starting/Resuming study: {study_name} ---\")\n",
    "    print(f\"--- Database at: {study_db_path} ---\")\n",
    "\n",
    "    try:\n",
    "        study.optimize(\n",
    "            objective, \n",
    "            n_trials=N_TRIALS,\n",
    "            timeout=None,\n",
    "            gc_after_trial=True\n",
    "        ) \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"--- HPO interrupted by user. Study is saved. ---\")\n",
    "    \n",
    "    print(f\"--- Study complete ---\")\n",
    "    \n",
    "    # --- 5. PRINT RESULTS ---\n",
    "    pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "    completed_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "    \n",
    "    print(f\"Total trials: {len(study.trials)}\")\n",
    "    print(f\"  Completed: {len(completed_trials)}\")\n",
    "    print(f\"  Pruned:    {len(pruned_trials)}\")\n",
    "\n",
    "    if completed_trials:\n",
    "        print(f\"\\nBest trial:\")\n",
    "        best_trial = study.best_trial\n",
    "        print(f\"  Value (min val_loss): {best_trial.value:.6f}\")\n",
    "        print(f\"  Params: \")\n",
    "        for key, value in best_trial.params.items():\n",
    "            print(f\"    {key}: {value}\")\n",
    "    else:\n",
    "        print(\"No trials completed successfully.\")\n",
    "    \n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "902c287b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 14:38:59,530] Using an existing study with name 'DTMPNN_hpo_gd' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting/Resuming study: DTMPNN_hpo_gd ---\n",
      "--- Database at: sqlite:///notebooks/hyperparams_search/HPO_reports/dashboard/master_hpo_study.db ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 14:46:55,748] Trial 51 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 15. ---\n",
      "Trial 51 was pruned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 14:50:06,381] Trial 52 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 6. ---\n",
      "Trial 52 was pruned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 15:16:52,837] Trial 53 finished with value: 0.2586904537219268 and parameters: {'lr': 0.0019215732323425677, 'weight_decay': 1.9545838402942607e-06, 'gd_weight': 0.0013655666413148622, 'graph_hidden_dim': 64, 'latent_dim': 32, 'context_dim': 16, 'graph_layers': 3}. Best is trial 43 with value: 0.22746023054306325.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Full log successfully finalized and written to: trial_53.log ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 15:19:33,015] Trial 54 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 5. ---\n",
      "Trial 54 was pruned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 15:22:14,193] Trial 55 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 5. ---\n",
      "Trial 55 was pruned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 15:36:32,416] Trial 56 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 30. ---\n",
      "Trial 56 was pruned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 15:50:56,762] Trial 57 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 27. ---\n",
      "Trial 57 was pruned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 15:54:03,319] Trial 58 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 5. ---\n",
      "Trial 58 was pruned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 15:57:17,767] Trial 59 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 6. ---\n",
      "Trial 59 was pruned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 15:59:28,211] Trial 60 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 5. ---\n",
      "Trial 60 was pruned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 16:34:42,400] Trial 61 finished with value: 0.30038498387886925 and parameters: {'lr': 0.0012225379349194712, 'weight_decay': 6.5366654949903755e-06, 'gd_weight': 0.0020397623811694815, 'graph_hidden_dim': 64, 'latent_dim': 32, 'context_dim': 16, 'graph_layers': 5}. Best is trial 43 with value: 0.22746023054306325.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Full log successfully finalized and written to: trial_61.log ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 17:10:26,074] Trial 62 finished with value: 0.2578068522306589 and parameters: {'lr': 0.0015599654300943553, 'weight_decay': 6.8610544705611225e-06, 'gd_weight': 0.0020885603570798363, 'graph_hidden_dim': 64, 'latent_dim': 32, 'context_dim': 16, 'graph_layers': 5}. Best is trial 43 with value: 0.22746023054306325.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Full log successfully finalized and written to: trial_62.log ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 17:46:11,843] Trial 63 finished with value: 0.2839798535291965 and parameters: {'lr': 0.0014715943600803396, 'weight_decay': 5.9140780871704e-06, 'gd_weight': 0.0020075789738053865, 'graph_hidden_dim': 64, 'latent_dim': 32, 'context_dim': 16, 'graph_layers': 5}. Best is trial 43 with value: 0.22746023054306325.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Full log successfully finalized and written to: trial_63.log ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 17:49:46,463] Trial 64 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 5. ---\n",
      "Trial 64 was pruned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 17:56:11,797] Trial 65 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 9. ---\n",
      "Trial 65 was pruned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 17:59:46,323] Trial 66 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 5. ---\n",
      "Trial 66 was pruned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 18:03:20,955] Trial 67 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 5. ---\n",
      "Trial 67 was pruned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 18:18:22,019] Trial 68 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 21. ---\n",
      "Trial 68 was pruned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 18:54:25,087] Trial 69 finished with value: 0.2204171061515808 and parameters: {'lr': 0.001593760129459641, 'weight_decay': 1.0546290780917184e-05, 'gd_weight': 0.001013983616183676, 'graph_hidden_dim': 64, 'latent_dim': 32, 'context_dim': 64, 'graph_layers': 5}. Best is trial 69 with value: 0.2204171061515808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Full log successfully finalized and written to: trial_69.log ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 19:23:13,998] Trial 70 pruned.               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Trial pruned at epoch 40. ---\n",
      "Trial 70 was pruned.\n",
      "--- Study complete ---\n",
      "Total trials: 71\n",
      "  Completed: 21\n",
      "  Pruned:    49\n",
      "\n",
      "Best trial:\n",
      "  Value (min val_loss): 0.220417\n",
      "  Params: \n",
      "    lr: 0.001593760129459641\n",
      "    weight_decay: 1.0546290780917184e-05\n",
      "    gd_weight: 0.001013983616183676\n",
      "    graph_hidden_dim: 64\n",
      "    latent_dim: 32\n",
      "    context_dim: 64\n",
      "    graph_layers: 5\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Run the HPO Study ---\n",
    "if __name__ == \"__main__\":\n",
    "    Path(\"notebooks/hyperparams_search/HPO_reports\").mkdir(exist_ok=True)\n",
    "    Path(\"notebooks/hyperparams_search/HPO_reports/dashboard\").mkdir(exist_ok=True)\n",
    "    study = run_study()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vle-dtmpnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
