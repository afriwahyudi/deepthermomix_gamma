{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1acade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "os.chdir(\"../..\")\n",
    "print(os.getcwd())\n",
    "\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8' \n",
    "seed = 21\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.use_deterministic_algorithms(False)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10995fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data_pipeline import DataPipeline\n",
    "pipeline = DataPipeline(components_csv='datasets/components.csv')\n",
    "canonical_data, graph_list = pipeline.run_pipeline(raw_csv='datasets/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb19f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules.datasplit_module as dsm\n",
    "random.shuffle(graph_list)\n",
    "train, val, test = \\\n",
    "    dsm.system_disjoint_split(graph_list, random_state=seed, stratify_by_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fefa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train[:1000],\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    "    follow_batch=['component_batch']\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val[:1000],\n",
    "    batch_size=1024,\n",
    "    shuffle=False,\n",
    "    follow_batch=['component_batch']\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test[:1000],\n",
    "    batch_size=1024,\n",
    "    shuffle=False,\n",
    "    follow_batch=['component_batch']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bbf9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Configuration ---\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "constraint_type = 'hard'\n",
    "include_gd = False\n",
    "N_TRIALS = 10\n",
    "N_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed26e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "import modules.trainer_module as tm\n",
    "import modules.dtmpnn as gm\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import sys\n",
    "\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Constraint Type: {constraint_type}\")\n",
    "print(f\"Include GD: {include_gd}\")\n",
    "print(f\"Trials: {N_TRIALS}\")\n",
    "print(f\"Epochs per trial: {N_EPOCHS}\")\n",
    "\n",
    "def objective(trial: optuna.trial.Trial):\n",
    "    \"\"\"\n",
    "    This function takes an optuna 'trial' object,\n",
    "    builds a model, trains it, and returns the best validation loss.\n",
    "    \"\"\"\n",
    "    log_dir = Path(f\"notebooks/hyperparams_search/HPO_reports/optuna_logs/{constraint_type}_constraint/GD_backprop_{include_gd}\")\n",
    "    log_dir.mkdir(exist_ok=True, parents=True)\n",
    "    log_file_path = log_dir / f'trial_{trial.number}.log'\n",
    "\n",
    "    # --- 1. DEFINE THE HYPERPARAMETER SEARCH SPACE ---\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-7, 1e-4, log=True)\n",
    "    gd_weight = 1.0\n",
    "    graph_hidden_dim = trial.suggest_categorical('graph_hidden_dim', [16, 32, 64, 128])\n",
    "    latent_dim = trial.suggest_categorical('latent_dim', [16, 32, 64])\n",
    "    context_dim = trial.suggest_categorical('context_dim', [16, 32, 64])\n",
    "    graph_layers = trial.suggest_int('graph_layers', 2, 5)\n",
    "\n",
    "    # --- 2. RUN THE TRIAL ---\n",
    "    try:\n",
    "        model = gm.DTMPNN(\n",
    "            node_dim=train[0].x.shape[1],\n",
    "            edge_dim=train[0].edge_attr.shape[1],\n",
    "            graph_hidden_dim=graph_hidden_dim,\n",
    "            latent_dim=latent_dim,\n",
    "            context_dim=context_dim,\n",
    "            graph_layers=graph_layers,\n",
    "            constraint_type=constraint_type\n",
    "        ).to(device)\n",
    "\n",
    "        trainer = tm.DTMPNNTrainer(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            test_loader=test_loader,\n",
    "            include_gd=include_gd,\n",
    "            device=device,\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay,\n",
    "            gd_weight=gd_weight\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        trainer.train(\n",
    "            epochs=N_EPOCHS,\n",
    "            save_dir=None,\n",
    "            log_file_path=log_file_path,\n",
    "            save_best=False,\n",
    "            save_every=None,\n",
    "            optuna_trial=trial\n",
    "        )\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # --- 3. RETURN THE METRIC TO MINIMIZE ---\n",
    "        return trainer.best_val_loss\n",
    "\n",
    "    except optuna.TrialPruned:\n",
    "        print(f\"Trial {trial.number} was pruned.\")\n",
    "        torch.cuda.empty_cache()\n",
    "        raise\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Trial {trial.number} failed with error: {e}\", file=sys.stderr)\n",
    "        torch.cuda.empty_cache()\n",
    "        return float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0f4e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Study Runner ---\n",
    "def run_study():\n",
    "    pruner = MedianPruner(\n",
    "        n_startup_trials=5,\n",
    "        n_warmup_steps=5,\n",
    "        interval_steps=1\n",
    "    )\n",
    "    \n",
    "    study_name = f\"DTMPNN_hpo_{constraint_type}_constrained_{'gd' if include_gd else 'no_gd'}\"\n",
    "    study_db_path = f\"sqlite:///notebooks/hyperparams_search/HPO_reports/dashboard/master_hpo_study.db\"\n",
    "    \n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        storage=study_db_path,\n",
    "        load_if_exists=True,\n",
    "        direction='minimize',\n",
    "        pruner=pruner\n",
    "    )\n",
    "    \n",
    "    print(f\"--- Starting/Resuming study: {study_name} ---\")\n",
    "    print(f\"--- Database at: {study_db_path} ---\")\n",
    "\n",
    "    try:\n",
    "        study.optimize(\n",
    "            objective, \n",
    "            n_trials=N_TRIALS,\n",
    "            timeout=None,\n",
    "            gc_after_trial=True\n",
    "        ) \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"--- HPO interrupted by user. Study is saved. ---\")\n",
    "    \n",
    "    print(f\"--- Study complete ---\")\n",
    "    \n",
    "    # --- 5. PRINT RESULTS ---\n",
    "    pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "    completed_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "    \n",
    "    print(f\"Total trials: {len(study.trials)}\")\n",
    "    print(f\"  Completed: {len(completed_trials)}\")\n",
    "    print(f\"  Pruned:    {len(pruned_trials)}\")\n",
    "\n",
    "    if completed_trials:\n",
    "        print(f\"\\nBest trial:\")\n",
    "        best_trial = study.best_trial\n",
    "        print(f\"  Value (min val_loss): {best_trial.value:.6f}\")\n",
    "        print(f\"  Params: \")\n",
    "        for key, value in best_trial.params.items():\n",
    "            print(f\"    {key}: {value}\")\n",
    "    else:\n",
    "        print(\"No trials completed successfully.\")\n",
    "    \n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902c287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Run the HPO Study ---\n",
    "if __name__ == \"__main__\":\n",
    "    Path(\"notebooks/hyperparams_search/HPO_reports\").mkdir(exist_ok=True)\n",
    "    Path(\"notebooks/hyperparams_search/HPO_reports/dashboard\").mkdir(exist_ok=True)\n",
    "    study = run_study()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vle-dtmpnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
