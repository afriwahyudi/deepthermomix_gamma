{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0ea82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.chdir(\"../..\")\n",
    "print(os.getcwd())\n",
    "\n",
    "import torch\n",
    "from modules.amine_blend_pipeline import AmineBlendPipeline\n",
    "import modules.datasplit_module as dsm\n",
    "from modules.model_loader import load_model\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# --- Reproducibility settings ---\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8' \n",
    "seed = 21\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.use_deterministic_algorithms(False)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05117cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Process data ---\n",
    "pipeline = AmineBlendPipeline(components_csv='datasets/components.csv')\n",
    "canonical_data, graph_list = pipeline.run_pipeline(raw_csv='datasets/dataset.csv')\n",
    "pipeline.save_canonical_df(canonical_data, 'datasets/canonical_data.csv')\n",
    "random.shuffle(graph_list)\n",
    "train_raw, val_raw, test_raw, train_std, val_std, test_std, stats = \\\n",
    "    dsm.standardized_system_disjoint_split(graph_list, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f592c150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model, stats = load_model('notebooks/inference_phase/model_weights/best_model.pt', return_stats=True)\n",
    "model = model.to('cuda')\n",
    "# Load data\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_std,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    follow_batch=['component_batch']\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_std,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    follow_batch=['component_batch']\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_std,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    follow_batch=['component_batch']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0ea979",
   "metadata": {},
   "source": [
    "## GRAPH BLOCK ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5542110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Process data ---\n",
    "pipeline = AmineBlendPipeline(components_csv='datasets/components.csv')\n",
    "data_gamma, graph_gamma = pipeline.run_pipeline(raw_csv='datasets/data_gamma.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e7e788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Standardize the graph_gamma data using existing stats\n",
    "from copy import deepcopy\n",
    "\n",
    "graph_gamma_std = []\n",
    "for data in graph_gamma:\n",
    "    data_std = deepcopy(data)\n",
    "    data_std.T = (data.T - stats['T']['mean']) / stats['T']['std']\n",
    "    data_std.T_mean = stats['T']['mean']\n",
    "    data_std.T_std = stats['T']['std']\n",
    "    graph_gamma_std.append(data_std)\n",
    "\n",
    "print(f\"Standardized {len(graph_gamma_std)} data points\")\n",
    "print(f\"First sample: {graph_gamma_std[0].component_names}\")\n",
    "print(f\"Mole fractions range: {graph_gamma_std[0].component_mole_frac} to {graph_gamma_std[-1].component_mole_frac}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670b434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Standardize temperature and extract latent vectors\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "model.eval()\n",
    "\n",
    "x_1_list = []\n",
    "gamma_1_list = []\n",
    "gamma_h2o_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in graph_gamma:\n",
    "        data_std = deepcopy(data)\n",
    "        data_std.T = (data.T - stats['T']['mean']) / stats['T']['std']\n",
    "        data_std.T_mean = stats['T']['mean']\n",
    "        data_std.T_std = stats['T']['std']\n",
    "        loader = DataLoader(\n",
    "            dataset=[data_std],\n",
    "            batch_size=1,\n",
    "            shuffle=False,\n",
    "            follow_batch=['component_batch']\n",
    "        )\n",
    "        batched_data = next(iter(loader)).to('cuda')\n",
    "        \n",
    "        # Extract latent vectors\n",
    "        node_emb, comp_emb = model.graph_block(batched_data.x, batched_data.edge_index, \n",
    "                                                batched_data.edge_attr, batched_data.mol_batch)\n",
    "        \n",
    "        mixture_embs, latent_vectors, mole_frac = model.mixture_layer(\n",
    "            comp_emb, \n",
    "            batched_data.component_mole_frac,\n",
    "            batched_data.component_batch_batch,\n",
    "            batched_data.T,\n",
    "            batched_data.T_std,\n",
    "            batched_data.T_mean,\n",
    "            track_grad=False\n",
    "        )\n",
    "        \n",
    "        # Calculate gamma_i\n",
    "        gamma_i = latent_vectors.mean(dim=1).cpu().numpy()\n",
    "        \n",
    "        x_1 = batched_data.component_mole_frac[0].cpu().item()\n",
    "        x_1_list.append(x_1)\n",
    "        gamma_1_list.append(gamma_i[0])\n",
    "        gamma_h2o_list.append(gamma_i[1])\n",
    "\n",
    "print(f\"Extracted {len(x_1_list)} points\")\n",
    "print(f\"x_MDEA range: {min(x_1_list):.3f} to {max(x_1_list):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76be5d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Plot activity coefficients\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Convert to arrays and sort by x_MEA\n",
    "x_1_array = np.array(x_1_list)\n",
    "gamma_1_array = np.array(gamma_1_list)\n",
    "gamma_h2o_array = np.array(gamma_h2o_list)\n",
    "\n",
    "sorted_idx = np.argsort(x_1_array)\n",
    "x_1_sorted = x_1_array[sorted_idx]\n",
    "gamma_1_sorted = gamma_1_array[sorted_idx]\n",
    "gamma_h2o_sorted = gamma_h2o_array[sorted_idx]\n",
    "\n",
    "# Plot\n",
    "\"\"\" ax.plot(x_1_sorted, gamma_1_sorted, 'o-', linewidth=2.5, markersize=8, \n",
    "        label='γ_1', color='#1f77b4') \"\"\"\n",
    "ax.plot(x_1_sorted, gamma_h2o_sorted, 's-', linewidth=2.5, markersize=8, \n",
    "        label='γ_H2O', color='#2ca02c')\n",
    "\n",
    "ax.set_xlabel('Mole fraction of Amine (x_1)', fontsize=14)\n",
    "ax.set_ylabel('Activity coefficient (γᵢ)', fontsize=14)\n",
    "ax.set_title('Activity Coefficients vs Composition\\nMDEA + H2O at T=313 K', \n",
    "             fontsize=15, fontweight='bold')\n",
    "ax.set_xscale('linear')\n",
    "ax.grid(True, alpha=0.3, which='both')\n",
    "ax.legend(fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Activity coefficient plot complete!\")\n",
    "print(f\"γ_1 range: {gamma_1_sorted.min():.4f} to {gamma_1_sorted.max():.4f}\")\n",
    "print(f\"γ_H2O range: {gamma_h2o_sorted.min():.4f} to {gamma_h2o_sorted.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e733687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Calculate excess Gibbs energy\n",
    "R = 8.314  # J/(mol·K)\n",
    "T = 313.15  # K\n",
    "\n",
    "# Calculate G_excess for each component\n",
    "G_excess_1 = gamma_1_sorted * R * T\n",
    "G_excess_h2o = gamma_h2o_sorted * R * T\n",
    "\n",
    "# Calculate molar excess Gibbs energy of mixing\n",
    "x_h2o_sorted = 1 - x_1_sorted  # x_H2O = 1 - x_1\n",
    "G_excess_mix = R * T * (x_1_sorted * np.log(gamma_1_sorted) + x_h2o_sorted * np.log(gamma_h2o_sorted))\n",
    "\n",
    "print(f\"G_excess_1 range: {G_excess_1.min():.2f} to {G_excess_1.max():.2f} J/mol\")\n",
    "print(f\"G_excess_H2O range: {G_excess_h2o.min():.2f} to {G_excess_h2o.max():.2f} J/mol\")\n",
    "print(f\"G_excess_mix range: {G_excess_mix.min():.2f} to {G_excess_mix.max():.2f} J/mol\")\n",
    "\n",
    "# Plot excess Gibbs energy\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "ax.plot(x_1_sorted, G_excess_mix, 'o-', linewidth=2.5, markersize=8, \n",
    "        label='G^E_mix', color='#d62728')\n",
    "\n",
    "ax.set_xlabel('Mole fraction of Amine (x_1)', fontsize=14)\n",
    "ax.set_ylabel('Excess Gibbs Energy (J/mol)', fontsize=14)\n",
    "ax.set_title('Excess Gibbs Energy of Mixing\\nAmine + H2O at T=313 K', \n",
    "             fontsize=15, fontweight='bold')\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.grid(True, alpha=0.3, which='both')\n",
    "ax.legend(fontsize=13)\n",
    "ax.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc97c7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract latent vectors for all compositions\n",
    "def extract_latent_vectors(group_df, test_std, device='cuda'):\n",
    "    \"\"\"\n",
    "    Extract latent vectors for one composition at one pco2 point.\n",
    "    Returns: latent_vectors (tensor), component_names, mass_fractions\n",
    "    \"\"\"\n",
    "    # Use first data point from the group\n",
    "    idx = group_df.iloc[0]['index']\n",
    "    base_data = test_std[idx]\n",
    "    \n",
    "    # Create DataLoader\n",
    "    loader = DataLoader(\n",
    "        dataset=[base_data],\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        follow_batch=['component_batch']\n",
    "    )\n",
    "    \n",
    "    batched_data = next(iter(loader)).to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _, latent_vectors, comp_emb = model(batched_data)\n",
    "    \n",
    "    return latent_vectors, batched_data.component_names, batched_data.component_mass_frac\n",
    "\n",
    "print(\"Function ready. What plot format do you want?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bf7b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter for T=298.15 K and extract data closest to pco2=15 kPa\n",
    "target_T = 298.15\n",
    "target_pco2 = 15.0\n",
    "\n",
    "# Check if this temperature exists in system 62\n",
    "system_62_data = df_test[df_test['system_id'] == 62]\n",
    "available_temps = system_62_data['T'].unique()\n",
    "print(f\"Available temperatures for System 62: {sorted(available_temps)}\")\n",
    "\n",
    "# Find closest temperature if 298.15 doesn't exist\n",
    "if target_T not in available_temps:\n",
    "    closest_T = min(available_temps, key=lambda x: abs(x - target_T))\n",
    "    print(f\"T={target_T} K not found. Using closest: T={closest_T} K\")\n",
    "    target_T = closest_T\n",
    "\n",
    "# Filter data\n",
    "system_data = df_test[(df_test['system_id'] == 62) & (df_test['T'] == target_T)]\n",
    "\n",
    "if len(system_data) == 0:\n",
    "    print(\"No data found! Let's check what systems have data at 298.15 K:\")\n",
    "    temp_check = df_test[df_test['T'] == target_T]\n",
    "    print(temp_check.groupby('system_id')['component_names'].first())\n",
    "else:\n",
    "    print(f\"\\nFound {len(system_data)} points at T={target_T} K\")\n",
    "    print(f\"Available compositions: {system_data['mole_fractions'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db45d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Extract latent vectors for each composition at pco2 ≈ 15 kPa\n",
    "target_T = 313.15\n",
    "target_pco2 = 15.0\n",
    "\n",
    "system_data = df_test[(df_test['system_id'] == 62) & (df_test['T'] == target_T)]\n",
    "comp_groups = system_data.groupby('mole_fractions')\n",
    "\n",
    "results = []\n",
    "\n",
    "for mole_frac, group in comp_groups:\n",
    "    # Find point closest to target pco2\n",
    "    group_sorted = group.iloc[(group['pco2'] - target_pco2).abs().argsort()]\n",
    "    closest_row = group_sorted.iloc[0]\n",
    "    \n",
    "    idx = closest_row['index']\n",
    "    base_data = test_std[idx]\n",
    "    \n",
    "    # Extract latent vectors\n",
    "    loader = DataLoader(\n",
    "        dataset=[base_data],\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        follow_batch=['component_batch']\n",
    "    )\n",
    "    batched_data = next(iter(loader)).to('cuda')\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _, latent_vectors, _ = model(batched_data)\n",
    "    \n",
    "    # Calculate gamma_i (mean across latent dimensions)\n",
    "    gamma_i = latent_vectors.mean(dim=1).cpu().numpy()\n",
    "    \n",
    "    results.append({\n",
    "        'mole_fractions': mole_frac,\n",
    "        'gamma_i': gamma_i,\n",
    "        'pco2_actual': closest_row['pco2'],\n",
    "        'component_names': base_data.component_names\n",
    "    })\n",
    "\n",
    "print(f\"Extracted latent vectors for {len(results)} compositions\")\n",
    "print(f\"Component order: {results[0]['component_names']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d052f127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Plot activity coefficients vs mole fraction\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Extract data for plotting\n",
    "x_pz = [r['mole_fractions'][0] for r in results]  # PZ mole fraction\n",
    "x_tea = [r['mole_fractions'][1] for r in results]  # TEA mole fraction\n",
    "x_h2o = [r['mole_fractions'][2] for r in results]  # H2O mole fraction\n",
    "\n",
    "gamma_pz = [r['gamma_i'][0] for r in results]\n",
    "gamma_tea = [r['gamma_i'][1] for r in results]\n",
    "gamma_h2o = [r['gamma_i'][2] for r in results]\n",
    "\n",
    "# Sort by PZ mole fraction for smooth lines\n",
    "sorted_indices = np.argsort(x_pz)\n",
    "x_pz_sorted = np.array(x_pz)[sorted_indices]\n",
    "gamma_pz_sorted = np.array(gamma_pz)[sorted_indices]\n",
    "gamma_tea_sorted = np.array(gamma_tea)[sorted_indices]\n",
    "gamma_h2o_sorted = np.array(gamma_h2o)[sorted_indices]\n",
    "\n",
    "# Plot\n",
    "ax.plot(x_pz_sorted, gamma_pz_sorted, 'o-', linewidth=2, markersize=8, label='γ_PZ', color='#1f77b4')\n",
    "ax.plot(x_pz_sorted, gamma_tea_sorted, 's-', linewidth=2, markersize=8, label='γ_TEA', color='#ff7f0e')\n",
    "ax.plot(x_pz_sorted, gamma_h2o_sorted, '^-', linewidth=2, markersize=8, label='γ_H2O', color='#2ca02c')\n",
    "\n",
    "ax.set_xlabel('Mole fraction of PZ (x_PZ)', fontsize=13)\n",
    "ax.set_ylabel('Activity coefficient (γᵢ)', fontsize=13)\n",
    "ax.set_title(f'Activity Coefficients vs Composition\\nSystem 62: PZ + TEA + H2O at T={target_T} K', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_yscale('log')\n",
    "ax.grid(True, alpha=0.3, which='both')\n",
    "ax.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Activity coefficient plot complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1696fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_batch(model, batched_data, device='cpu'):\n",
    "    \"\"\"\n",
    "    Perform forward pass and analyze a single batch.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained GDMPNN model\n",
    "        batched_data: PyG Data object\n",
    "        device: Device to run on ('cpu' or 'cuda')\n",
    "    \n",
    "    Returns:\n",
    "        dict: Analysis results including predictions and intermediate values (all as tensors)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    batched_data = batched_data.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_pred, latent_vectors, comp_emb = model(batched_data)\n",
    "    \n",
    "    # Unstandardize values\n",
    "    T_actual = batched_data.T * batched_data.T_std + batched_data.T_mean\n",
    "    pco2_actual = batched_data.pco2 * batched_data.pco2_std + batched_data.pco2_mean\n",
    "    \n",
    "    # Calculate thermodynamic quantities\n",
    "    R = 8.314  # Gas constant J/(mol·K)\n",
    "    gamma_i = latent_vectors.mean(dim=1).view(1, -1)\n",
    "    G_excess = gamma_i * R * T_actual.view(-1, 1)\n",
    "    G_excess_sum = G_excess.sum(dim=1)\n",
    "    comp_emb_mean = comp_emb.mean(dim=1).view(1, -1)\n",
    "    \n",
    "    torch.set_printoptions(precision=2, sci_mode=False)\n",
    "    # Print formatted output\n",
    "    print(\"\\n\" + \"=\"*120)\n",
    "    print(\"FORWARD PASS INPUTS:\")\n",
    "    print(\"=\"*120)\n",
    "    print(f\"Component names                     : {batched_data.component_names}\")\n",
    "    print(f\"Component mass fractions            : {batched_data.component_mass_frac}\")\n",
    "    print(f\"Component mole fractions            : {batched_data.component_mole_frac}\")\n",
    "    print(f\"System temperature                  : {T_actual} Kelvin\")\n",
    "    print(f\"Partial pressure of CO2             : {pco2_actual} kPa\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*120)\n",
    "    print(\"FORWARD PASS OUTPUTS:\")\n",
    "    print(\"=\"*120)\n",
    "    print(f\"Predicted CO2 solubility            : {y_pred.detach()}\")\n",
    "    print(f\"Actual CO2 solubility               : {batched_data.aco2}\")\n",
    "    print(f\"Absolute error                      : {torch.abs(y_pred - batched_data.aco2).detach()}\")\n",
    "    print(f\"Relative error (%)                  : {(torch.abs(y_pred - batched_data.aco2) / batched_data.aco2 * 100).detach()}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*120)\n",
    "    print(\"SOLVENT SUBSYSTEM ANALYSIS:\")\n",
    "    print(\"=\"*120)\n",
    "    print(f\"Aggregated latent vector (γᵢ)       : {gamma_i.detach()}\")\n",
    "    print(f\"Excess Gibbs Energy (Gᵢ_excess)     : {G_excess.detach()} J/mol\")\n",
    "    print(f\"Sum of Excess Gibbs Energy          : {G_excess_sum.detach()} J/mol\")\n",
    "    print(f\"Aggregated component embedding      : {comp_emb_mean.detach()}\")\n",
    "    print(\"=\"*120 + \"\\n\")\n",
    "    \n",
    "    # Return results as dict (all tensors)\n",
    "    results = {\n",
    "        'component_names': batched_data.component_names,\n",
    "        'mass_fractions': batched_data.component_mass_frac,\n",
    "        'mole_fractions': batched_data.component_mole_frac,\n",
    "        'temperature': T_actual,\n",
    "        'pco2': pco2_actual,\n",
    "        'predicted_aco2': y_pred.detach(),\n",
    "        'actual_aco2': batched_data.aco2,\n",
    "        'absolute_error': torch.abs(y_pred - batched_data.aco2).detach(),\n",
    "        'relative_error': (torch.abs(y_pred - batched_data.aco2) / batched_data.aco2 * 100).detach(),\n",
    "        'latent_vectors': latent_vectors.detach(),\n",
    "        'gamma_i': gamma_i.detach(),\n",
    "        'G_excess': G_excess.detach(),\n",
    "        'G_excess_sum': G_excess_sum.detach(),\n",
    "        'component_embeddings': comp_emb.detach(),\n",
    "        'comp_emb_mean': comp_emb_mean.detach()\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def analyze_sample(model, dataset, sample_idx, device='cpu'):\n",
    "    \"\"\"\n",
    "    Analyze a specific sample from the dataset.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained GDMPNN model\n",
    "        dataset: PyG dataset\n",
    "        sample_idx: Index of the sample to analyze\n",
    "        device: Device to run on ('cpu' or 'cuda')\n",
    "    \n",
    "    Returns:\n",
    "        dict: Analysis results (all tensors)\n",
    "    \"\"\"\n",
    "    loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        follow_batch=['component_batch']\n",
    "    )\n",
    "    \n",
    "    for i, batched_data in enumerate(loader):\n",
    "        if i == sample_idx:\n",
    "            return analyze_batch(model, batched_data, device)\n",
    "    \n",
    "    raise IndexError(f\"Sample index {sample_idx} not found in dataset of size {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971f3bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = analyze_sample(model, test_std, sample_idx=45, device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b848cd1a",
   "metadata": {},
   "source": [
    "## EQUILIBRIUM CURVE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84f03d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "# Step 1: Get the base system\n",
    "base_data = test_std[0]\n",
    "\n",
    "# Unstandardize the original values to see what we're working with\n",
    "T_unstd = base_data.T * base_data.T_std + base_data.T_mean\n",
    "pco2_unstd = base_data.pco2 * base_data.pco2_std + base_data.pco2_mean\n",
    "\n",
    "print(f\"System ID: {base_data.system_id}\")\n",
    "print(f\"System type: {base_data.system_type}\")\n",
    "print(f\"Components: {base_data.component_names}\")\n",
    "print(f\"Mole fractions: {base_data.component_mole_frac}\")\n",
    "print(f\"Temperature: {T_unstd:.2f} K\")\n",
    "print(f\"Original pco2: {pco2_unstd:.2f} kPa\")\n",
    "print(f\"Original aco2: {base_data.aco2:.4f}\")\n",
    "\n",
    "# Step 2: Create pco2 sweep (1 to 1000 kPa, 100 points, log scale)\n",
    "pco2_range_unstd = np.logspace(np.log10(1), np.log10(1000), 100)\n",
    "\n",
    "# Step 3: Standardize the pco2 values (convert tensors to float)\n",
    "pco2_mean = base_data.pco2_mean.item() if torch.is_tensor(base_data.pco2_mean) else base_data.pco2_mean\n",
    "pco2_std = base_data.pco2_std.item() if torch.is_tensor(base_data.pco2_std) else base_data.pco2_std\n",
    "\n",
    "pco2_range_std = (pco2_range_unstd - pco2_mean) / pco2_std\n",
    "\n",
    "# Step 4: Create copies of the data with varying pco2\n",
    "data_list = []\n",
    "for pco2_std_val in pco2_range_std:\n",
    "    data_copy = base_data.clone()\n",
    "    data_copy.pco2 = torch.tensor(pco2_std_val, dtype=torch.float32)\n",
    "    data_list.append(data_copy)\n",
    "\n",
    "print(f\"Created {len(data_list)} data points for inference\")\n",
    "print(f\"pco2 range (unstd): {pco2_range_unstd[0]:.2f} to {pco2_range_unstd[-1]:.2f} kPa\")\n",
    "# Step 5: Run inference directly on the list\n",
    "model.eval()\n",
    "predictions = []\n",
    "pco2_actual_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in data_list:\n",
    "        # Create a mini-batch using DataLoader to handle component_batch_batch\n",
    "        temp_loader = DataLoader(\n",
    "            dataset=[data],\n",
    "            batch_size=1,\n",
    "            shuffle=False,\n",
    "            follow_batch=['component_batch']\n",
    "        )\n",
    "        \n",
    "        batched_data = next(iter(temp_loader))\n",
    "        batched_data = batched_data.to('cuda')\n",
    "        \n",
    "        y_pred, _, _ = model(batched_data)\n",
    "        predictions.append(y_pred.cpu().item())\n",
    "        \n",
    "        # Store actual pco2 for verification\n",
    "        pco2_actual = (batched_data.pco2 * batched_data.pco2_std + batched_data.pco2_mean).cpu().item()\n",
    "        pco2_actual_list.append(pco2_actual)\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "pco2_actual_list = np.array(pco2_actual_list)\n",
    "\n",
    "print(f\"Inference complete!\")\n",
    "print(f\"Prediction range: {predictions.min():.4f} to {predictions.max():.4f}\")\n",
    "print(f\"pco2 check: {pco2_actual_list[0]:.2f} to {pco2_actual_list[-1]:.2f} kPa\")\n",
    "# Step 6: Plot the equilibrium curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(pco2_actual_list, predictions, 'b-', linewidth=2, label='Model prediction')\n",
    "plt.scatter([pco2_unstd], [base_data.aco2], color='red', s=100, zorder=5, \n",
    "            label=f'Original data point (pCO₂={pco2_unstd:.2f} kPa)')\n",
    "\n",
    "plt.xlabel('pCO₂ (kPa)', fontsize=12)\n",
    "plt.ylabel('αCO₂ (mol CO₂/mol amine)', fontsize=12)\n",
    "plt.title(f'CO₂ Equilibrium Curve\\n{base_data.system_type}: {base_data.component_names}\\nT = {T_unstd:.2f} K', \n",
    "          fontsize=13)\n",
    "plt.xscale('log')\n",
    "plt.grid(True, alpha=0.3, which='both')\n",
    "plt.legend(fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSystem info:\")\n",
    "print(f\"  Components: {base_data.component_names}\")\n",
    "print(f\"  Mole fractions: {base_data.component_mole_frac.cpu().numpy()}\")\n",
    "print(f\"  Temperature: {T_unstd:.2f} K\")\n",
    "print(f\"  pCO₂ range: {pco2_actual_list[0]:.2f} - {pco2_actual_list[-1]:.2f} kPa\")\n",
    "print(f\"  αCO₂ range: {predictions.min():.4f} - {predictions.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136591e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Analyze test set to find unique equilibrium systems\n",
    "import pandas as pd\n",
    "\n",
    "# Extract key info from each test sample\n",
    "test_info = []\n",
    "for i, data in enumerate(test_std):\n",
    "    T_unstd = (data.T * data.T_std + data.T_mean).item()\n",
    "    pco2_unstd = (data.pco2 * data.pco2_std + data.pco2_mean).item()\n",
    "    \n",
    "    # Convert mole fractions to tuple for grouping\n",
    "    mole_frac_tuple = tuple(data.component_mole_frac.cpu().numpy().round(4))\n",
    "    \n",
    "    test_info.append({\n",
    "        'index': i,\n",
    "        'system_id': data.system_id,\n",
    "        'component_names': str(data.component_names),\n",
    "        'mole_fractions': mole_frac_tuple,\n",
    "        'T': round(T_unstd, 2),\n",
    "        'pco2': pco2_unstd,\n",
    "        'aco2': data.aco2,\n",
    "        'system_type': data.system_type\n",
    "    })\n",
    "\n",
    "df_test = pd.DataFrame(test_info)\n",
    "\n",
    "# Group by system characteristics\n",
    "grouped = df_test.groupby(['system_id', 'component_names', 'mole_fractions', 'T'])\n",
    "\n",
    "print(f\"Total test samples: {len(test_std)}\")\n",
    "print(f\"Number of unique equilibrium curves: {len(grouped)}\")\n",
    "print(f\"\\nFirst 10 unique systems:\")\n",
    "print(grouped.size().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1d68b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the breakdown\n",
    "print(f\"Unique systems (by system_id): {df_test['system_id'].nunique()}\")\n",
    "print(f\"Unique equilibrium curves (system + T + composition): {len(grouped)}\")\n",
    "print(f\"\\nBreakdown by system_id:\")\n",
    "system_breakdown = df_test.groupby('system_id').agg({\n",
    "    'T': lambda x: len(x.unique()),  # number of unique temperatures\n",
    "    'pco2': 'count'  # total data points\n",
    "}).rename(columns={'T': 'num_temperatures', 'pco2': 'num_datapoints'})\n",
    "print(system_breakdown.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9fc57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Filter curves with at least N data points\n",
    "min_points = 5\n",
    "filtered_groups = grouped.filter(lambda x: len(x) >= min_points).groupby(['system_id', 'component_names', 'mole_fractions', 'T'])\n",
    "print(f\"Curves with >= {min_points} points: {len(filtered_groups)}\")\n",
    "\n",
    "# Option 2: Show distribution of points per curve\n",
    "points_per_curve = grouped.size()\n",
    "print(f\"\\nDistribution of data points per curve:\")\n",
    "print(points_per_curve.describe())\n",
    "print(f\"\\nCurves with 1 point: {(points_per_curve == 1).sum()}\")\n",
    "print(f\"Curves with 2-4 points: {((points_per_curve >= 2) & (points_per_curve <= 4)).sum()}\")\n",
    "print(f\"Curves with 5+ points: {(points_per_curve >= 5).sum()}\")\n",
    "print(f\"Curves with 10+ points: {(points_per_curve >= 10).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea54e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Select 6 random curves with >= 5 points\n",
    "min_points = 5\n",
    "filtered_groups = grouped.filter(lambda x: len(x) >= min_points).groupby(['system_id', 'component_names', 'mole_fractions', 'T'])\n",
    "\n",
    "# Sample 6 random curves\n",
    "import random\n",
    "random.seed(42)\n",
    "sampled_keys = random.sample(list(filtered_groups.groups.keys()), 6)\n",
    "\n",
    "print(f\"Selected 6 curves:\")\n",
    "for i, key in enumerate(sampled_keys):\n",
    "    system_id, comp_names, mole_frac, T = key\n",
    "    num_points = len(filtered_groups.get_group(key))\n",
    "    print(f\"{i+1}. System {system_id}: {comp_names}, T={T} K, {num_points} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c36e6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Function to generate equilibrium curve for a specific group\n",
    "def generate_equilibrium_curve(group_df, test_std, pco2_range=(1, 1000), num_points=100):\n",
    "    \"\"\"\n",
    "    Generate model predictions for an equilibrium curve.\n",
    "    \n",
    "    Args:\n",
    "        group_df: DataFrame slice for one equilibrium curve\n",
    "        test_std: Test dataset\n",
    "        pco2_range: (min, max) pco2 in kPa\n",
    "        num_points: Number of points to generate\n",
    "    \n",
    "    Returns:\n",
    "        pco2_sweep: Array of pco2 values (unstandardized)\n",
    "        aco2_pred: Array of predicted aco2 values\n",
    "        pco2_exp: Experimental pco2 values\n",
    "        aco2_exp: Experimental aco2 values\n",
    "    \"\"\"\n",
    "    # Get base data from first point in group\n",
    "    base_idx = group_df.iloc[0]['index']\n",
    "    base_data = test_std[base_idx]\n",
    "    \n",
    "    # Extract experimental points\n",
    "    pco2_exp = group_df['pco2'].values\n",
    "    aco2_exp = group_df['aco2'].values\n",
    "    \n",
    "    # Generate pco2 sweep\n",
    "    pco2_sweep_unstd = np.logspace(np.log10(pco2_range[0]), np.log10(pco2_range[1]), num_points)\n",
    "    \n",
    "    # Standardize\n",
    "    pco2_mean = base_data.pco2_mean.item()\n",
    "    pco2_std = base_data.pco2_std.item()\n",
    "    pco2_sweep_std = (pco2_sweep_unstd - pco2_mean) / pco2_std\n",
    "    \n",
    "    # Create data copies\n",
    "    data_list = []\n",
    "    for pco2_val in pco2_sweep_std:\n",
    "        data_copy = base_data.clone()\n",
    "        data_copy.pco2 = torch.tensor(pco2_val, dtype=torch.float32)\n",
    "        data_list.append(data_copy)\n",
    "    \n",
    "    # Run inference\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for data in data_list:\n",
    "            temp_loader = DataLoader(\n",
    "                dataset=[data],\n",
    "                batch_size=1,\n",
    "                shuffle=False,\n",
    "                follow_batch=['component_batch']\n",
    "            )\n",
    "            batched_data = next(iter(temp_loader))\n",
    "            batched_data = batched_data.to('cuda')\n",
    "            y_pred, _, _ = model(batched_data)\n",
    "            predictions.append(y_pred.cpu().item())\n",
    "    \n",
    "    return pco2_sweep_unstd, np.array(predictions), pco2_exp, aco2_exp\n",
    "\n",
    "print(\"Function defined. Ready to plot!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d13ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Plot the 6 example curves with formatted mass fractions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, key in enumerate(sampled_keys):\n",
    "    system_id, comp_names, mole_frac, T = key\n",
    "    group_df = filtered_groups.get_group(key)\n",
    "    \n",
    "    # Get base data to extract mass fractions\n",
    "    base_idx = group_df.iloc[0]['index']\n",
    "    base_data = test_std[base_idx]\n",
    "    \n",
    "    # Parse and format mass fractions\n",
    "    mass_fracs = [float(x) for x in base_data.component_mass_frac.split(' + ')]\n",
    "    mass_frac_str = ', '.join([f'{x:.2f}' for x in mass_fracs])\n",
    "    \n",
    "    # Format component names without brackets\n",
    "    comp_names_str = ', '.join(eval(comp_names))  # Convert string list to actual list\n",
    "    \n",
    "    # Generate curve\n",
    "    pco2_sweep, aco2_pred, pco2_exp, aco2_exp = generate_equilibrium_curve(group_df, test_std)\n",
    "    \n",
    "    # Plot\n",
    "    ax = axes[i]\n",
    "    ax.plot(pco2_sweep, aco2_pred, 'b-', linewidth=2, label='Model')\n",
    "    ax.scatter(pco2_exp, aco2_exp, color='red', s=80, zorder=5, label='Experimental', edgecolors='black', linewidths=1)\n",
    "    \n",
    "    ax.set_xlabel('pCO₂ (kPa)', fontsize=10)\n",
    "    ax.set_ylabel('αCO₂', fontsize=10)\n",
    "    ax.set_title(f'System {system_id}: {comp_names_str}\\nw = {mass_frac_str}, T = {T} K', fontsize=8)\n",
    "    ax.set_xscale('log')\n",
    "    ax.grid(True, alpha=0.3, which='both')\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Plotting complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32467beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which systems have multiple compositions at same temperature\n",
    "composition_variety = df_test.groupby(['system_id', 'component_names', 'T']).agg({\n",
    "    'mole_fractions': lambda x: len(set(x)),\n",
    "    'index': 'count'\n",
    "}).rename(columns={'mole_fractions': 'num_compositions', 'index': 'num_points'})\n",
    "\n",
    "# Filter for systems with multiple compositions at same T\n",
    "multi_comp = composition_variety[composition_variety['num_compositions'] > 1]\n",
    "print(f\"Systems with multiple compositions at same temperature:\")\n",
    "print(multi_comp.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f53358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract system 62 at T=313.15 K with all compositions\n",
    "target_system_id = 62\n",
    "target_T = 313.15\n",
    "\n",
    "# Filter the test dataframe\n",
    "system_data = df_test[(df_test['system_id'] == target_system_id) & \n",
    "                       (df_test['T'] == target_T)]\n",
    "\n",
    "# Group by composition\n",
    "comp_groups = system_data.groupby('mole_fractions')\n",
    "\n",
    "print(f\"System {target_system_id} at T={target_T} K\")\n",
    "print(f\"Number of different compositions: {len(comp_groups)}\")\n",
    "print(f\"\\nCompositions:\")\n",
    "for i, (mole_frac, group) in enumerate(comp_groups):\n",
    "    # Get mass fractions from first sample\n",
    "    idx = group.iloc[0]['index']\n",
    "    mass_frac_str = test_std[idx].component_mass_frac\n",
    "    print(f\"{i+1}. x={mole_frac}, w={mass_frac_str}, {len(group)} points\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pignn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
